
# Detecci√≥n de tr√°fico a√©reo en Sudam√©rica

### Intregrantes: 
* Ant√∫nez Alfaro, Max Bryam
* Castro Vergara, Rodrigo Alonso
* Escalante Ccoyllo,  Nah√≠a Alejandra
* Paico Reina, Aleksander Fabrizio
* Rojas Urquizo, Andr√©s Alejandro

## Introducci√≥n y justificaci√≥n del problema a resolver
El aumento constante del tr√°fico a√©reo mundial ha complicado la gesti√≥n del espacio a√©reo, creando desaf√≠os para la seguridad y eficiencia. Un problema clave es identificar a tiempo las zonas con alta congesti√≥n, donde muchas aeronaves coinciden o transitan simult√°neamente. Este proyecto propone un sistema en tiempo real para detectar zonas de congesti√≥n a√©rea en Sudam√©rica, ayudando a controladores y aeropuertos a visualizar √°reas con mayor densidad de vuelos. Mediante an√°lisis de Big data y mapas, busca optimizar rutas y reducir riesgos. 

## Descripci√≥n del dataset, origen y tama√±o de data
Para el desarrollo usamos la API de OpenSky Network (link), que nos proporciona datos gratuitos de aeronaves en tiempo real. A trav√©s de Kafka consumimos esa informaci√≥n cada minuto, solicitando la posici√≥n de todos los aviones sobre Am√©rica del Sur. Como la transmisi√≥n es continua, recibimos repetidamente datos del mismo avi√≥n en distintos minutos y, por tanto, en diferentes posiciones.
Al final, el dataset contendr√° las siguientes variables:
- icao24: la placa del avi√≥n
- callsign: Identificador para el control de tr√°fico a√©reo
- origin_country: Pa√≠s del que el avi√≥n ha salido
- time_position: Posici√≥n horaria en la que se encuentra la aeronave
- last_contact: El √∫ltimo contacto que tuvo
- longitude: Coordenadas
- latitude: Coordenadas
- baro_altitude: Altitud en la que se encuentra el avi√≥n
- on_ground: Booleano que indica si el avi√≥n est√° en tierra
- velocity: Velocidad a la que va el avi√≥n
- heading: √Ångulo de ataque del avi√≥n
- timestamp_ingest: Momento en el que la data fue consumida

## Dificultad t√©cnica
Procesamiento y ML a tiempo real

## Herramientas y/o tecnolog√≠as empleadas
1. Kafka: Para la ingesta de la data en tiempo real
2. Airflow: Para la orquestaci√≥n del ML Pipeline
3. Data Lake - S3: Usado para guardar toda la data que llega, incluso la que generamos nosotros
4. Data Lake - Databricks: Usado para guardar la data tras un procesamiento en tiempo real de la misma
5. Spark: Para hacer el procesamiento en tiempo real usando Spark Streaming
6. MLflow: Para la visualizaci√≥n de los experimentos de los algoritmos de ML
7. Power BI: Para la visualizaci√≥n de la data
8. Uso de AWS para la parte Cloud: La secci√≥n del uso de Kafka y la orquestaci√≥n son realizados en m√°quinas virtuales EC2, adem√°s, el almacenamiento del Data Lake son usados en S3.

## Indicaciones de ejecuci√≥n
El proyecto consta de 4 partes:
- Kafka
- Airflow
- Databricks
- Power BI

Cada una de estas secciones debe ser encendida manualmente.

### Kafka

Los scripts de Kafka se encuentran en un EC2. Para acceder:

```bash
ssh -i <ubicacion_del_pem>/labsuser.pem ec2-user@52.205.209.139
```

Dentro, debes ejecutar los containers principales:

```bash
docker start kafka zookeeper
```

Luego, accede a la carpeta `kafka/` y activa el entorno virtual:

```bash
source venv/bin/activate
```

Para crear el topic (opcional si ya existe):

```bash
python flight_topic.py
```

Para ejecutar el **consumer** (recomendado iniciar primero):

```bash
python flight_consumer.py
```

Para ejecutar el **producer**:

```bash
python flight_producer.py
```

> üí° Se recomienda usar `tmux` o abrir otra terminal para correr ambos procesos al mismo tiempo.  
> El consumer se usa para almacenar la data en el Data Lake.

---

### Airflow

Accede al EC2:

```bash
ssh -i <ubicacion_del_pem>/labsuser.pem ubuntu@44.209.38.71
```

Activa el entorno virtual:

```bash
source airflow-py/venv/bin/activate
```

Ejecuta Airflow:

```bash
airflow scheduler
airflow webserver
```

Ejecuta la UI de MLflow:

```bash
mlflow ui --backend-store-uri /home/ubuntu/mlruns --host 0.0.0.0 --port 8082
```

- **UI Airflow**: [http://44.209.38.71:8080](http://44.209.38.71:8080)
- **UI MLflow**: [http://44.209.38.71:8082](http://44.209.38.71:8082)

Para iniciar el flujo de trabajo, ir al DAG `MLPipeline` y activarlo manualmente. Esto recolectar√° la data del d√≠a anterior desde S3, la procesar√° y generar√° resultados y m√©tricas en MLflow.

---

### Databricks

Para usar la secci√≥n del Data Lake, el producer de Kafka debe estar encendido, ya que se reciben datos en tiempo real desde la API.

El procesamiento en Databricks est√° optimizado para serverless. En lugar de un stream continuo, se usan micro-lotes procesados mediante triggers cada 15 minutos.  
Todo el flujo se automatiza con un **Databricks Job** programado para cada 15 minutos, asegurando la actualizaci√≥n constante.

---

### Power BI

La visualizaci√≥n se realiza en Power BI conect√°ndose por **DirectQuery** a la tabla Delta Lake en Databricks.  
Esto asegura dashboards siempre actualizados con los micro-lotes nuevos.  
Las transformaciones se hacen en Databricks y en Power BI solo se enfocan en visualizaci√≥n y medidas DAX cuando es necesario.





## Arquitectura del proyecto
![Vista general](imagenes/pipeline_little_data.svg)
Enlace: [Imagen completa](https://excalidraw.com/#room=8aa0eac536892d50bc29,IdKkZRdkRXOSZVbFQ2dmNw)

### Ingesta de Datos (Kafka)

- **Origen**: Datos de vuelos capturados desde la API de OpenSky Network.
- **Productor Kafka**: Conecta con la API cada minuto y transmite los datos de ubicaci√≥n a√©rea.
- **Consumidor EC2**: Una instancia EC2 recibe los mensajes y env√≠a los datos al data lake en S3.
- **Consumer Databricks**: V√≠a Spark Streaming, se reciben y procesan los datos en tiempo real antes de ser almacenados de forma estructurada.

---

### Almacenamiento en S3 (Data Lake)

Se organiza en diferentes capas:

- **S3 (raw)**: Datos en crudo directamente desde Kafka.
- **S3 (concatenated)**: Datos concatenados por hora mediante la funci√≥n `flight_processor2` en Lambda.
- **S3 (daily-joined)**: Resultado final del d√≠a, generado por `daily_flight_1` (Lambda). B√°sicamente es una concatenaci√≥n de todos los datos por hora.

---

### Procesamiento (Airflow)

- Se orquesta con scripts Python para limpieza y generaci√≥n de features usando Airflow.
- Se extraen datos diarios (`daily_extractor`), que obtiene los datos del d√≠a anterior al momento de iniciar la orquestaci√≥n y los compila en CSV (`CSV_compiler.py`).
- Para la primera parte se aplican dos etapas de preprocesamiento:
  - `preprocessing_part_1.py`
  - `preprocessing_part_2.py`

---

### Entrenamiento de Modelos (Airflow)

- Se entrena el modelo de Machine Learning con Scikit-learn dentro de la misma orquestaci√≥n de Airflow:
  - `DENStream_model.py` para clustering.
- Los modelos se almacenan en S3:
  - **S3 (denstream)**
- Para visualizar los resultados se usa MLflow.

---

### Procesamiento en Streaming (Spark Streaming)

- Usamos Spark Streaming para leer datos nuevos directamente del t√≥pico de Kafka con `spark.readStream`.
- Procesa los datos y crea features en tiempo real, como `estado_de_vuelo` o `Indicador_Congestion`.
- Opera en micro-lotes (trigger) y guarda los resultados en una tabla Delta Lake gobernada por Unity Catalog.

---

### Visualizaci√≥n (Power BI)

- Se conecta a Databricks con **DirectQuery**, asegurando que los datos se muestren en tiempo real.
- Recibe datos ya limpios y transformados, enfoc√°ndose √∫nicamente en la capa de visualizaci√≥n y en el c√°lculo de funciones DAX.

## Describir c√≥mo los datos ser√°n extra√≠dos, transformados y cargados (ETL/ELT)

Utilizamos Kafka para conectarnos con la API de Open Sky Network, la cual env√≠a la informaci√≥n a dos consumidores en la instancia EC2. El primer consumidor se encarga del proceso ELT para alimentar el modelo de machine learning, mientras que el segundo realiza el proceso ETL para generar las visualizaciones.

El primer flujo comienza con Kafka funcionando como productor, el cual se conecta a la API de Open Sky Network para obtener datos en tiempo real. Esta informaci√≥n se env√≠a a dos consumidores en una instancia EC2 escritos en Python. A trav√©s de un Lambda intermedio llamado flight_processor, los datos se almacenan primero en el datalake de S3 en la carpeta raw. Luego, la funci√≥n Lambda flight_processor2 se encarga de concatenar los archivos por hora (cada 30 minutos) y guarda el resultado en un bucket de S3 llamado concatenated. Finalmente, la funci√≥n Lambda daily_flight_1 concatena toda la informaci√≥n acumulada durante el d√≠a (programada a las 20:50) y almacena el resultado final en una carpeta del S3 llamada daily_joined. Una vez que los datos diarios est√°n consolidados en el bucket daily_joined de S3, se activa la funci√≥n Lambda daily_extractor, la cual extrae estos datos procesados y los env√≠a al script csv_compiler.py. Este script se encarga de compilar y transformar los datos en archivos csv listos para su an√°lisis. Despu√©s, se inicia la etapa de procesamiento. Esta fase se orquesta con Airflow y scripts en Python, donde se realiza la limpieza de datos y la creaci√≥n de nuevas features. Para ello, se ejecutan los scripts preprocessing_part_1.py y preprocessing_part_2.py, preparando los datos para el modelado. Seguidamente, se entrena un modelo basado en el algoritmo DENStream mediante DENStream_model.py, y durante el entrenamiento se usa scikit-learn, river y MLflow para gestionar experimentos, guardar los modelos en formato .pkl y realizar la predicci√≥n de resultados, permitiendo comparar m√©tricas y par√°metros de forma estructurada. Una vez finalizado el entrenamiento, entra en acci√≥n la funci√≥n Lambda model_denstream, la cual se encarga de tomar el modelo entrenado y gestionar su env√≠o al datalake en S3. Esta Lambda act√∫a como un puente automatizado que facilita el almacenamiento seguro y organizado en la carpeta denstream del bucket, asegurando que el modelo final quede disponible y versionado para futuras consultas, evaluaciones o integraciones. Con este paso, el flujo cierra el ciclo de procesamiento y entrenamiento, dejando el modelo listo y almacenado en la nube.

El segundo flujo comienza con la API de OpenSky Network, desde donde se obtiene informaci√≥n en tiempo real sobre el tr√°fico a√©reo. Kafka act√∫a como productor, conect√°ndose a esta API para recibir y distribuir los datos.
Esta informaci√≥n se env√≠a a un consumidor configurado con Spark Streaming en Databricks. Durante esta etapa de procesamiento en streaming, Spark lee los datos a medida que llegan y aplica una serie de transformaciones:
Parseo y Estructuraci√≥n: Los mensajes binarios crudos de Kafka son parseados usando un esquema predefinido, convirtiendo los datos JSON en un DataFrame estructurado.
Enriquecimiento y Creaci√≥n de Features:
Los timestamps de posici√≥n e ingesta se convierten a formatos de fecha/hora legibles.
La altitud se convierte de metros a pies y la velocidad de m/s a km/h.
Se crean columnas categ√≥ricas como estado_de_vuelo, Indicador_Congestion y Cuadrante (cuadrante geogr√°fico).
Se extraen componentes de fecha y hora (d√≠a, mes, hora) para un an√°lisis granular.
Carga en Delta Lake: Los datos procesados se cargan en una tabla Delta llamada flights_gold utilizando el m√©todo .toTable(), que es compatible con Unity Catalog. Para gestionar los datos y los checkpoints de forma segura, se utilizan los Vol√∫menes de Unity Catalog, evitando problemas de ruteo directo en DBFS.
Finalmente, para la etapa de visualizaci√≥n, Power BI se conecta directamente a la tabla flights_gold en el Data Lake de Databricks. Esta conexi√≥n directa permite la creaci√≥n del dashboard que refleja el estado casi en tiempo real del tr√°fico a√©reo, facilitando un monitoreo continuo.
Las principales visualizaciones creadas incluyen:

Tarjetas de KPI: Muestran m√©tricas en tiempo real como Vuelos Totales, Velocidad Promedio (km/h), Altitud Promedio (pies), Porcentaje de Congesti√≥n y Vuelos Cr√≠ticos.
Gr√°fico de Dona: Representa la distribuci√≥n de vuelos seg√∫n su estado actual (Crucero, Espera/Ascenso, Maniobra, Tierra).
Gr√°fico de Barras Apiladas: Compara la distribuci√≥n de los estados de vuelo entre diferentes pa√≠ses de origen (Brasil, EE.UU., Chile, Colombia, Argentina).
Diagrama de Dispersi√≥n: Correlaciona la velocidad de vuelo con la altitud, donde los puntos est√°n coloreados por estado de vuelo para identificar patrones operativos y anomal√≠as.
Mapa Geoespacial Interactivo: Ubica cada vuelo en su localizaci√≥n en tiempo real. El color de cada punto indica el estado del vuelo y su tama√±o puede representar el nivel de congesti√≥n o criticidad, permitiendo una f√°cil identificaci√≥n de las zonas de alto tr√°fico.


## Resultados obtenidos y an√°lisis
Los datos procesados y almacenados en el Data Lake permitieron visualizar zonas con alta concentraci√≥n de vuelos mediante dashboards interactivos en Power BI, facilitando la identificaci√≥n de posibles zonas de congesti√≥n a√©rea.

Gracias al preprocesamiento y la generaci√≥n de features, el modelo entrenado(DENStream) mostr√≥ una alta capacidad para detectar patrones y predecir posibles acumulaciones futuras de tr√°fico a√©reo. Las m√©tricas obtenidas y registradas en MLflow permitieron comparar distintas configuraciones y ajustar los par√°metros de los modelos para mejorar la precisi√≥n.

Vimos que al usar el algoritmo de DENStream sobre la data en diferentes d√≠as (tener en cuenta que la data que obtenemos es del dia del anterior al que estamos haciendo la prueba del modelo), el silhouette score, sale muy similar, lo cual nos da a entender que la estructura espacial de los datos (agrupamiento de los aviones por posici√≥n), no cambia dr√°sticamente, y eso es una se√±al de consistencia de los patrones de tr√°fico a√©reo diario para la regi√≥n y escala temporal que estamos evaluando. 

![Vista general](imagenes/silo1.png)
![Vista general](imagenes/silo2.png)

Seg√∫n esto, podemos ver que el tr√°fico a√©reo en la regi√≥n es regular, predecible y tiene baja variabilidad diaria, lo cual es una informaci√≥n √∫til a la hora de hacer la planificaci√≥n operativa.

Adem√°s de la detecci√≥n de cl√∫steres de congesti√≥n con DENStream, se logr√≥ implementar un modelo de series de tiempo basado en LSTM, dise√±ado para predecir la congesti√≥n a√©rea futura, basado en datos hist√≥ricos. Aunque su integraci√≥n en el pipeline de AWS a√∫n no se ha completado, el modelo fue desarrollado y probado exitosamente en un entorno local, demostrando su potencial para anticipar la congesti√≥n a√©rea.

El proceso se llev√≥ a cabo de la siguiente manera:

1. Preparaci√≥n y Ventaneo de Datos: Se implement√≥ un preprocesamiento para transformar los datos agregados en "ventanas" de tiempo, estructurando la informaci√≥n en secuencias con un lookback (pasos hacia atr√°s) para predecir un horizon (pasos futuros).

2. Entrenamiento y Optimizaci√≥n: Utilizando PyTorch, se construy√≥ y entren√≥ un modelo LSTM. Se realiz√≥ una b√∫squeda sistem√°tica de hiperpar√°metros y se utiliz√≥ MLflow para registrar los experimentos y seleccionar la configuraci√≥n m√°s √≥ptima.

3. Evaluaci√≥n y Simulaci√≥n: El mejor modelo fue evaluado contra datos de validaci√≥n. 

![Vista general](imagenes/prediccion1.png)
![Vista general](imagenes/prediccion2.png)

El modelo LSTM funciona excelentemente para predicciones t√°cticas a corto plazo (ej. pr√≥ximos minutos) y es muy √∫til para alertas estrat√©gicas a largo plazo. Si bien no puede predecir el valor exacto de la congesti√≥n con 30 minutos de antelaci√≥n, s√≠ puede advertir de manera fiable si se espera que el tr√°fico aumente o disminuya significativamente, cumpliendo con el objetivo central del proyecto.




## Dificultades identificadas al momento de implementar la soluci√≥n
- Conectar el producer de kafka a un consumer en Databricks: A la hora de querer hacer la conexi√≥n con Databricks desde AWS, en un inicio la informaci√≥n que encontramos, nos dec√≠a que no se podr√≠a usar la cuenta de community edition para Spark Streaming, por restricciones, por lo que optamos por usar una cuenta de free edition. El problema es que esta cuenta ten√≠a limitaciones con respecto a los clusters y trabajo con data por streaming. Decidimos pasar a una cuenta de free try, pero esta ten√≠a el mismo problema. Al final vimos que con la cuenta de community edition pod√≠amos hacer la recepci√≥n de los datos por streaming, pero con la limitaci√≥n que ten√≠amos que cambiar de cluster cada vez que uno se cerraba.
- Hacer conexiones con el S3 para almacenar la informaci√≥n y sobre todo para extraerla: En un inicio esper√°bamos hacer conecciones directas desde el EC2 al S3 pero por restricciones del rol que tenemos (rol de estudiante), no era posible, por lo que hicimos conecciones a trav√©s de lambdas. Esto nos permite tambi√©n personalizar la hora de ejecuci√≥n de cada lambda. Adem√°s, el problema m√°s grande que tuvimos aqu√≠ fue a la hora de extraer informaci√≥n del S3, ya que necesit√°bamos permisos especiales, que al final logramos obtener. Principalmente, estas son las razones por la que la √∫nica vez que extraemos informaci√≥n del S3 es al inicio del ML Pipeline, adem√°s, evitamos hacer accesos al S3 de forma que omitamos crear m√°s lambdas y tener m√°s dificultades al respecto. Internamente en el EC2, creamos carpetas de archivos temporales para almacenar la informaci√≥n de un script a otro en el orquestador de AirFlow.
- Ca√≠das en los servicios de AWS: En varias ocasiones, los servidores de AWS sufrieron varias ca√≠das. Esto no es la primera vez que pasa, los servidores de estudiante de AWS son muy propensos a que se caigan. Esto hace que no podamos hacer actualizaciones en el sistema y no podamos trabajar directamente en el pipeline por varias horas.
- Uso del Airflow (desde el EC2 ubuntu y desde MacOS): Desde un inicio, tuvimos problemas para instalar y ejecutar Airflow en MacOS, lo cual nos  limitaba a la hora de hacer pruebas. Intentamos instalaciones desde Docker, usando docker-file custom y oficiales, pero en ninguno de los casos nos sirvi√≥. Siempre ten√≠amos un problema con el worker, el scheduler o incluso con el webserver. A la hora de usar Airflow en EC2, tuvimos los mismos problemas, incluso tuvimos problemas a la hora de hacer ejecuciones, ya que AirFlow pod√≠a llegar a ser muy pesado, por lo que tuvimos que usar m√°quinas virtuales m√°s grandes y con m√°s almacenamiento. Aun as√≠, Airflow desde Docker no nos funcion√≥ en ning√∫n momento, por lo que optamos por ir con una versi√≥n directamente desde Python, siguiendo las instrucciones de este repositorio de GitHub 
Enlace: [Repositorio](https://github.com/hitchon1/setup-airflow-ec2), logramos solucionar los problemas que tuvimos. Para el caso de MacOS, lamentablemente a√∫n no logramos solucionar el problema, las pruebas que hicimos posteriormente fueron directamente en el EC2.
- Limitaciones del Streaming en Databricks Serverless: El enfoque inicial de un pipeline de streaming continuo no fue viable. Los cl√∫steres Serverless de Databricks no soportan flujos infinitos por defecto, lo que oblig√≥ a redise√±ar la arquitectura hacia un modelo de micro-lotes activado por disparadores (trigger).
- Conflictos de Permisos con Unity Catalog: Durante la fase de escritura, aparecieron errores de permisos como ‚ÄúPublic DBFS root is disabled‚Äù. Esto se debi√≥ a Unity Catalog, que bloquea el acceso directo a las rutas de DBFS. La soluci√≥n fue adoptar el uso de ‚ÄúVolumes‚Äù de Unity Catalog para gestionar los datos y los checkpoints.
- Integraci√≥n del Modelo LSTM en el Pipeline de AWS: A pesar de haber desarrollado y validado exitosamente el modelo LSTM basado en PyTorch en un entorno de desarrollo, surgieron dificultades significativas al intentar integrarlo en el pipeline automatizado en AWS y no se logr√≥ la adaptaci√≥n del modelo para que fuera compatible con el flujo de datos orquestado. Debido a estas complejidades, se decidi√≥ posponer su despliegue final.

![Vista general](imagenes/visual1.png)
![Vista general](imagenes/visual2.png)


- La √∫ltima hora de monitorizaci√≥n cubri√≥ 37 000 vuelos en toda Sudam√©rica, lo que confirma que el sistema captura eficazmente el tr√°fico regional. La velocidad promedio registrada fue de 612,5 km/h, concentrada mayoritariamente entre 550 y 700 km/h, lo que coincide con los reg√≠menes de crucero habituales. La altitud media fue de 24 100 pies, tambi√©n dentro del rango de crucero comercial (FL240‚ÄìFL360). Solo el 6,35 % de los vuelos se agrupan en zonas de alta densidad (m√°s de cinco aeronaves en un √°rea de 10√ó10 millas n√°uticas), lo que indica que la saturaci√≥n global es baja y las alertas ser√°n selectivas. Detectamos adem√°s 10 000 vuelos cr√≠ticos, definidos como aquellos con maniobras at√≠picas o altitudes fuera del rango esperado; estas rutas deben revisarse para garantizar la seguridad.
- La distribuci√≥n por estado muestra que 7 088 vuelos (‚âà19 %) estaban en crucero, seguidos de 2 971 en espera o ascenso y 2 883 en maniobra, mientras menos de mil estaban en tierra, confirmando el foco en el tr√°fico activo. Brasil aporta 13 000 vuelos, EE. UU. 2 000, Chile 3 000 y Colombia y Argentina cifras menores, lo que revela una comunicaci√≥n intra-regional muy intensa, especialmente con Brasil. El diagrama de dispersi√≥n Altitud vs Velocidad presenta un c√∫mulo estable en torno a los rangos de crucero, y un peque√±o porcentaje (< 5 %) de puntos fuera de esos l√≠mites corresponde a fases de ascenso o descenso.

## Conclusiones
Conclusiones del ML Pipelines:
- Podemos concluir seg√∫n el lapso de tiempo que usamos para desarrollar el proyecto y visualizar los modelos, no tubimos una variaci√≥n en el tr√°fico a√©reo en general. Adem√°s, podemos notar por la formaci√≥n de los clusters que los aviones durante estos d√≠as, han seguido rutas muy similares entre s√≠.
- Tambi√©n cabe destacar que, en la regi√≥n en la que hicimos el experimento, generalmente no tiene un tr√°fico a√©reo fluctuante como en otras regiones como Am√©rica del Norte o Asia.


Conclusiones de An√°lisis Visualizaciones
- El sistema valida en vivo m√°s de 37 000 vuelos y demuestra una cobertura casi total del espacio a√©reo sudamericano y una capacidad consistente para distinguir fases de crucero, ascenso y maniobra terminal.
- Con un √≠ndice medio de congesti√≥n del 6,35 %, las zonas cr√≠ticas quedan muy delimitadas (menos del 10 % del √°rea total), lo que minimiza el ‚Äúruido‚Äù de alertas y garantiza que las intervenciones se centren s√≥lo donde realmente hay acumulaci√≥n de tr√°fico.
- La detecci√≥n de 10 000 vuelos con maniobras at√≠picas o altitudes fuera de umbral permite asignar recursos de revisi√≥n prioritaria, por ejemplo replanificar aproximaciones en aeropuertos de alta actividad o gestionar separaciones en tiempo real.
- La intensa participaci√≥n de Brasil (13 000 vuelos) subraya la necesidad de colaboraci√≥n regional para equilibrar flujos y mitigar cuellos de botella.
- Aplicar t√©cnicas de estimaci√≥n de densidad de kernel sobre los puntos de congesti√≥n para generar ‚Äúhotspots‚Äù temporales, y a partir de ellos ajustar din√°micamente la sectorizaci√≥n y los topes de flujo en horas punta.



Conclusiones T√©cnicas:
- Se us√≥ Databricks con un cluster Serverless mediante una arquitectura de micro-lotes con triggers, demostrando ser una soluci√≥n eficiente y compatible. La integraci√≥n con Unity Catalog para gestionar los vol√∫menes de datos y la carga simplificada con el m√©todo .toTable() permitieron el almacenamiento en una tabla Delta Lake. La automatizaci√≥n de todo el proceso con un Databricks Job que se ejecuta cada 15 minutos garantiza la actualizaci√≥n constante de los datos para su an√°lisis.
- Se logr√≥ crear un dashboard interactivo que visualiza eficazmente las zonas de alta concentraci√≥n de vuelos conect√°ndose directamente al Data Lake en Databricks. La conexi√≥n en DirectQuery a la tabla Delta Lake asegura que las visualizaciones se actualicen en tiempo real a medida que llegan nuevos datos. El dise√±o del dashboard incluye indicadores clave (KPIs), un mapa geoespacial y gr√°ficos de distribuci√≥n.
- Se hizo deploy del pipeline completamente en cloud, de forma que pueda correr sin la necesidad de depender de nuestro propio hardware o las configuraciones que tenemos en nuestras computadoras. 
- Se demostr√≥ la factibilidad y el alto potencial de utilizar modelos predictivos como las redes LSTM para anticipar la congesti√≥n a√©rea. Aunque su implementaci√≥n se complet√≥ exitosamente en un entorno de desarrollo, su integraci√≥n en el pipeline de nube automatizado qued√≥ como un trabajo futuro, evidenciando la brecha que a menudo existe entre el modelado y el despliegue operativo 


## Posibles mejoras
- Una mejora fundamental ser√≠a migrar a una versi√≥n de pago de Databricks. Esto permitir√≠a tener un cl√∫ster siempre activo, eliminando la necesidad de intervenciones manuales.
- Se podr√≠a mejorar el dashboard de PowerBI  implementando un sistema de alertas proactivas. Utilizando las capacidades de Power BI, se podr√≠an configurar notificaciones autom√°ticas que se disparen cuando los indicadores, como el Indicador_Congestion o el n√∫mero de Vuelos Cr√≠ticos, superen ciertos umbrales.
- Migrar a un AWS de pago, para poder mantener corriendo los sistemas sin tener que apagarlos.
- Agregar el modelo de LSTM al ML Pipeline. En un inicio se ten√≠a planeado tener el lstm en funcionamiento, pero tras los problemas que tuvimos con AirFlow, retras√≥ la implementaci√≥n de Modelos de ML adicionales que ten√≠amos planeado, por lo que decidimos no ponerlo de momento.
- Integraci√≥n de una UI para facilitar el acceso a los modelos usados, asi como agregar nuevos enlaces a los hiperparametros para que los usuarios los puedan modificar de forma r√°pida.
- Mayor seguridad a la hora de hacer acceso al S3 y a los EC2 principalmente.
- Integrar el modelo LSTM en el pipeline de producci√≥n de AWS: Dado que el modelo LSTM ya fue desarrollado y validado, el siguiente paso cr√≠tico es completar su despliegue en la nube. Esto permitir√≠a que el sistema no solo visualice la congesti√≥n actual, sino que tambi√©n ofrezca pron√≥sticos automatizados.

